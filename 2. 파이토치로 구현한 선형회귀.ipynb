{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMb5BqQK0+cJVp3W3h8dLAd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. 선형 회귀 분석**\n","선형 회귀 분석(Linear Regression)은 주어진 데이터에서 입력 변수(독립 변수)와 출력 변수(종속 변수) 사이의 관계를 직선(또는 다차원에서는 평면)으로 설명하고, 새로운 입력 값에 대한 출력을 예측하는 통계 및 머신러닝 기법입니다. 예를 들어, 공부 시간(입력 변수)과 시험 점수(출력 변수) 사이의 관계를 분석해 \"공부 시간이 늘어날수록 시험 점수가 증가한다\"는 패턴을 찾아냅니다. 이 과정에서 선형 회귀는 \"Y = W X + b\"라는 수식(기울기 W와 절편 b)으로 데이터를 표현하며, 최적의 기울기와 절편을 찾기 위해 비용 함수(Cost Function)를 최소화하는 경사 하강법(Gradient Descent) 등의 알고리즘을 사용합니다. 최종적으로 선형 회귀 모델은 주어진 입력 값에 대해 가장 적합한 예측 결과를 제공합니다.\n","\n"],"metadata":{"id":"MKizVnk07dE7"}},{"cell_type":"markdown","source":["# **2. 단항 선형 회귀**\n","단항 선형 회귀(Simple Linear Regression)는 하나의 독립 변수(입력 변수, X)를 사용하여 하나의 종속 변수(출력 변수, Y)를 예측하는 통계 및 머신러닝 기법입니다. 입력 변수와 출력 변수 사이의 관계를 직선(Linear Line)으로 나타내며, 데이터의 패턴을 기반으로 가장 잘 맞는 직선을 찾아내어 새로운 입력 값에 대한 출력을 예측합니다."],"metadata":{"id":"siadhp-b72pY"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn  # 파이토치를 이용해서 모델을 만들 때 필요한 모듈. (신경망 생성시 필요한 모듈)\n","import torch.optim as optim  # 경사하강법에 필요한 최적화 알고리즘을 구현하는 패키지.\n","import matplotlib.pyplot as plt\n","\n","torch.manual_seed(2025)\n","\n","x_train = torch.FloatTensor([[1], [2], [3]])\n","y_train = torch.FloatTensor([[2], [4], [6]])\n","\n","print(x_train, x_train.shape)\n","print(y_train, y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhmqz9a79WXk","executionInfo":{"status":"ok","timestamp":1753409564685,"user_tz":-540,"elapsed":12,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"8ae43c64-9ea3-423a-ad6e-822ee453222d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [2.],\n","        [3.]]) torch.Size([3, 1])\n","tensor([[2.],\n","        [4.],\n","        [6.]]) torch.Size([3, 1])\n"]}]},{"cell_type":"code","source":["plt.figure(figsize=(6, 4))\n","plt.scatter(x_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"oQZlqs1Y-V5P","executionInfo":{"status":"ok","timestamp":1753409565055,"user_tz":-540,"elapsed":371,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"347eb6bd-c959-4a6e-ddc2-9a4d84acf261"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7c24096a7310>"]},"metadata":{},"execution_count":54},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# y = wx + b # -1 ~ 1 범위 내에서 무작위로 선택\n","\n","model = nn.Linear(1, 1)\n","print(model)\n","\n"," # nn.Linear(in_features=1, out_features=1)의 줄임 표현. 입력값 하나를 받아서 출력값 하나를 내보내는 선형 계층(Linear Layer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulDSnlqc-cuF","executionInfo":{"status":"ok","timestamp":1753409565058,"user_tz":-540,"elapsed":51,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"6b42fe91-4aea-450b-c769-a34605a0af45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=1, out_features=1, bias=True)\n"]}]},{"cell_type":"code","source":["y_pred = model(x_train)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYvtcETe_K1h","executionInfo":{"status":"ok","timestamp":1753409565059,"user_tz":-540,"elapsed":45,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"dc97ccbf-c7ce-446f-b3ee-66b330407f45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.2410],\n","        [1.6109],\n","        [1.9809]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["print(list(model.parameters()))\n","# tensor([[0.3699]] : Weight\n","#  requires_grad=True ; 미분을 통해 계속 변화될 값\n","#  tensor([0.8711]: bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yxj4LCoTAWG2","executionInfo":{"status":"ok","timestamp":1753409565060,"user_tz":-540,"elapsed":38,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"0b1c5e79-0319-4402-960a-530bb20b734e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[0.3699]], requires_grad=True), Parameter containing:\n","tensor([0.8711], requires_grad=True)]\n"]}]},{"cell_type":"code","source":["# y = Wx + b\n","print(0.3699*1 + 0.8711)\n","print(0.3699*2 + 0.8711)\n","print(0.3699*3 + 0.8711)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ummWtlmLACtH","executionInfo":{"status":"ok","timestamp":1753409565061,"user_tz":-540,"elapsed":31,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"43512be7-a1b5-4aba-9c1b-8888c3e7cce7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.241\n","1.6109\n","1.9808000000000001\n"]}]},{"cell_type":"markdown","source":["\n","\n","# **손실 함수**\n","\n","손실 함수(Loss Function)는 머신러닝과 딥러닝 모델이 예측한 값과 실제 값 사이의 차이를 수치적으로 나타내는 함수입니다. 모델이 학습을 통해 최적의 결과를 도출하려면 이 차이를 최소화해야 합니다. 손실 함수는 예측값과 실제값의 오차를 계산하여 하나의 숫자(스칼라 값)로 반환하며, 이 값은 비용(Cost) 또는 오차(Error)라고도 불립니다. 예를 들어, 회귀 문제에서는 주로 평균 제곱 오차(MSE, Mean Squared Error)를 사용하여 예측값과 실제값 간의 평균적인 차이를 측정하고, 분류 문제에서는 교차 엔트로피 손실(Cross-Entropy Loss)을 사용해 예측 확률 분포와 실제 레이블 분포 간의 차이를 계산합니다. 손실 함수가 반환한 값은 역전파(Backpropagation)를 통해 모델의 가중치와 편향을 조정하는 데 사용됩니다. 즉, 손실 함수는 모델이 학습 과정에서 목표로 삼아야 할 방향을 알려주는 나침반 역할을 합니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FcylqtP%2FbtsLBsQ8oy1%2FAAAAAAAAAAAAAAAAAAAAAIK4QXrEjeqm1c59U9mbMldsWvVgz2Gx7b5tY9I5apus%2Fimg.webp%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3DiUFdoPVkwLAAIndIE3FEsXmqako%253D'>"],"metadata":{"id":"gITvnOsZ76zr"}},{"cell_type":"code","source":["((y_pred - y_train)**2).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_2veC7ZC9Bk","executionInfo":{"status":"ok","timestamp":1753409565079,"user_tz":-540,"elapsed":18,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"ac50dcba-7088-4d95-831b-4feb36d910ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.4790, grad_fn=<MeanBackward0>)"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["loss = nn.MSELoss()(y_pred, y_train)\n","loss\n","# __call()  : 객체를 상수로 사용할 수 있다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37EsP58X7_70","executionInfo":{"status":"ok","timestamp":1753409565079,"user_tz":-540,"elapsed":7,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"b27a1091-9e9f-48ad-b36f-77b1cb0fd559"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7.4790, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["### **최적화**\n","\n","최적화(Optimization)는 주어진 목표를 달성하기 위해 최상의 해결책(Optimal Solution)을 찾아가는 과정입니다. 머신러닝과 딥러닝에서는 주로 모델이 예측한 값과 실제 값 사이의 오차(손실 함수 값)를 최소화하는 것을 목표로 합니다. 이 과정에서 모델의 학습 가능한 파라미터(가중치와 편향)를 조정하여 손실 함수의 값을 점점 더 작게 만들어갑니다. 최적화는 주로 경사 하강법(Gradient Descent)과 같은 알고리즘을 사용해 수행되며, 손실 함수의 기울기(Gradient)를 따라가며 최저점(또는 최적점)을 찾습니다. 이 과정은 마치 산에서 가장 낮은 지점을 찾아 내려가는 것과 비슷합니다. 최적화는 단순히 손실을 줄이는 것뿐만 아니라, 학습 속도, 안정성, 과적합 방지와 같은 다양한 요소를 고려해야 하는 복합적인 과정입니다. 즉, 최적화는 모델이 데이터로부터 가장 정확하고 효율적인 예측을 할 수 있도록 파라미터를 조정하는 핵심 과정입니다."],"metadata":{"id":"KHLpvQ-nD7fd"}},{"cell_type":"markdown","source":["### **경사하강법**\n","\n","경사하강법(Gradient Descent)은 머신러닝과 딥러닝 모델이 최적의 가중치(Weights)와 편향(Biases)를 찾기 위해 손실 함수(Loss Function)를 최소화하는 방법입니다. 이 알고리즘은 마치 산 꼭대기에서 출발해 가장 낮은 지점(최솟값)을 찾아 내려가는 과정과 비슷합니다. 먼저, 모델은 손실 함수의 기울기(Gradient)를 계산합니다. 이 기울기는 현재 지점에서 손실이 가장 빠르게 감소하는 방향을 나타냅니다. 이후, 모델은 기울기의 반대 방향으로 가중치와 편향 값을 조금씩 업데이트합니다. 이때 학습률(Learning Rate)은 한 번에 이동하는 \"걸음의 크기\"를 결정합니다. 학습률이 너무 크면 최적의 지점을 지나칠 수 있고, 너무 작으면 학습 속도가 매우 느려질 수 있습니다. 이 과정을 반복하면서 손실 함수 값이 점점 작아지고, 결국 최적의 가중치와 편향을 찾아내게 됩니다. 즉, 경사하강법은 모델이 더 나은 예측을 할 수 있도록 가중치를 조정해주는 핵심 최적화 알고리즘입니다.\n","\n","경사하강법은 데이터를 어떻게 나눠서 학습하느냐에 따라 배치(Batch), 확률적(Stochastic), 미니배치(Mini-Batch)로 나뉩니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FdFPhqQ%2FbtsLB2q1has%2FAAAAAAAAAAAAAAAAAAAAAPXVv4eNnEcQELa1e6KeOUbPXsyZto1YxR8HN6kCzTjU%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3D%252FFfV7xFxgmogyrYQHwV1eHfL5v8%253D'>\n","\n"],"metadata":{"id":"riA_McMkD9rF"}},{"cell_type":"markdown","source":["### **학습률**\n","\n","학습률(Learning Rate)은 머신러닝과 딥러닝 모델이 학습할 때 가중치(Weights)와 편향(Biases)를 얼마나 크게 조정할지를 결정하는 하이퍼파라미터입니다. 경사하강법(Gradient Descent)과 같은 최적화 알고리즘에서 손실 함수(Loss Function)의 기울기(Gradient)를 따라 최적의 가중치를 찾아갈 때, 학습률은 한 번의 업데이트에서 이동하는 \"걸음의 크기\"를 의미합니다. 학습률이 너무 크면 최적의 가중치를 지나쳐 버리거나 학습이 불안정해질 수 있고, 너무 작으면 학습 속도가 매우 느려져 최적값에 도달하기 어려울 수 있습니다. 따라서 적절한 학습률을 선택하는 것은 모델의 학습 속도와 최적화 성능을 결정하는 중요한 요소입니다. 일반적으로 고정된 학습률을 사용하기도 하지만, 상황에 따라 학습률을 점진적으로 줄이거나 동적으로 조정하는 방법(예: Adam, Step Decay, Cyclical Learning Rate 등)이 사용되기도 합니다."],"metadata":{"id":"KUEKcWeIHZzr"}},{"cell_type":"markdown","source":["<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fbo7nTS%2FbtsLz8ezGG6%2FAAAAAAAAAAAAAAAAAAAAAKvthCVYixeejQQDXy10UR6_GVQjs-i0sUyaUwsBHHrB%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3DzeiSLhRwLLQUJcN8T6S1TrAKbsg%253D' width=500>"],"metadata":{"id":"b6FBGLPkPhCn"}},{"cell_type":"markdown","source":["### **가중치(Weight) 업데이트**\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FY7XP6%2FbtsLCG1WrrY%2FAAAAAAAAAAAAAAAAAAAAAAYoIFn9nWhT4wXq1p7Bi7cevDJxseZIwKZDVRHrsAyH%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3DRTIQn5rLGAKwf4xvwaxQKugzUz4%253D'>"],"metadata":{"id":"rcTEVOdmKauC"}},{"cell_type":"markdown","source":["### **편향(Bias) 업데이트**\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FcJTrjF%2FbtsLCIedndI%2FAAAAAAAAAAAAAAAAAAAAAFW3d5vHSFDeEcfb_SPyFC_yG5S7XDVYdioo6e9z3GTX%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3DegwpBZ%252FGBIG%252FuR5n6vVg7w2bxQs%253D'>"],"metadata":{"id":"4LFsBoZhLOTa"}},{"cell_type":"markdown","source":["### **가중치 업데이트의 예**\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fc39I43%2FbtsLA70z9TT%2FAAAAAAAAAAAAAAAAAAAAACohhCffeifRl2AdMxtMNKw5dEmV7QrfLBR3nXNDl6Y1%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1753973999%26allow_ip%3D%26allow_referer%3D%26signature%3Db%252FYq1z3jq4ImsxibBIytUsOaTrQ%253D' width=500>"],"metadata":{"id":"Vk-cJZoqLYkf"}},{"cell_type":"code","source":["optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# gradient를 초기화\n","optimizer.zero_grad()\n","# 역전파: 비용 함수를 미분하여 gradient(기울기) 계산\n","loss.backward()\n","# W와 b를 업데이트\n","optimizer.step()\n","\n","print(list(model.parameters())) # W: 0.2177, b: 0.7267"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"67Q5wYiXLvOT","executionInfo":{"status":"ok","timestamp":1753409565085,"user_tz":-540,"elapsed":8,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"27df3029-c744-457c-a106-10f896115cce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[0.4872]], requires_grad=True), Parameter containing:\n","tensor([0.9188], requires_grad=True)]\n"]}]},{"cell_type":"markdown","source":["```\n","[Parameter containing:\n","tensor([[0.3699]], requires_grad=True), Parameter containing:\n","tensor([0.8711], requires_grad=True)]\n","\n","1번 학습한 결과\n","[Parameter containing:\n","tensor([[0.4872]], requires_grad=True), Parameter containing:\n","tensor([0.9188], requires_grad=True)]\n","```\n"],"metadata":{"id":"QYL_vcagOCGu"}},{"cell_type":"code","source":["# 반복 학습을 통해 오차가 있는 W, b를 수정하면서 오차를 계속 줄여감.\n","# epochs: 반복 학습 횟수(에포크)\n","\n","epochs = 1000\n","\n","for epoch in range(epochs + 1):\n","    y_pred = model(x_train)\n","    loss = nn.MSELoss()(y_pred, y_train)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch: {epoch}/{epochs} Loss: {loss: .6f}')"],"metadata":{"id":"wPKitoLONK7O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753409565540,"user_tz":-540,"elapsed":456,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"125c4257-3348-4bad-c068-120a01fad95b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/1000 Loss:  5.963749\n","Epoch: 100/1000 Loss:  0.156203\n","Epoch: 200/1000 Loss:  0.096524\n","Epoch: 300/1000 Loss:  0.059646\n","Epoch: 400/1000 Loss:  0.036857\n","Epoch: 500/1000 Loss:  0.022776\n","Epoch: 600/1000 Loss:  0.014074\n","Epoch: 700/1000 Loss:  0.008697\n","Epoch: 800/1000 Loss:  0.005374\n","Epoch: 900/1000 Loss:  0.003321\n","Epoch: 1000/1000 Loss:  0.002052\n"]}]},{"cell_type":"code","source":["print(list(model.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kILMI49sOeEN","executionInfo":{"status":"ok","timestamp":1753409565564,"user_tz":-540,"elapsed":23,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"6d6b0036-bdc4-4b17-e7c2-611b6d76b00f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[1.9475]], requires_grad=True), Parameter containing:\n","tensor([0.1193], requires_grad=True)]\n"]}]},{"cell_type":"code","source":["# y = 1.9475x + 0.1193\n","x_test = torch.FloatTensor([[5]])\n","y_pred = model(x_test)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Obt6TPdOkde","executionInfo":{"status":"ok","timestamp":1753409565640,"user_tz":-540,"elapsed":74,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"27959737-e4e9-4e42-af31-9fd2685c4d20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[9.8569]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"code","source":["y = 1.9475*5 + 0.1193\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93n3T0OmPAMQ","executionInfo":{"status":"ok","timestamp":1753409565649,"user_tz":-540,"elapsed":8,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"299952de-cabc-4cf6-cb4c-bd3ff24f5578"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.856800000000002"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["# **3. 다중 선형 회귀**\n","\n","다중 선형 회귀(Multiple Linear Regression)는 여러 개의 독립 변수(입력 변수)를 사용해 하나의 종속 변수(출력 변수)를 예측하는 통계 및 머신러닝 기법입니다. 단순 선형 회귀가 하나의 독립 변수와 하나의 종속 변수 간의 선형 관계를 설명하는 반면, 다중 선형 회귀는 두 개 이상의 입력 변수가 출력 변수에 어떻게 영향을 미치는지를 분석합니다. 이 관계는 수식으로 표현되며, 예를 들어 Y=W1X1+W2X2+...+WnXn+b와 같이 나타납니다. 여기서 Y는 예측 값, X1,X2,...Xn ​은 입력 변수, W1,W2,...Wn ​은 각 변수의 가중치, b는 절편입니다. 다중 선형 회귀는 입력 변수들이 독립적이고, 종속 변수와 선형 관계를 가진다는 가정 하에 작동하며, 주로 경제학, 의료, 마케팅 등 다양한 분야에서 복합적인 요인의 영향을 분석하고 예측하는 데 사용됩니다."],"metadata":{"id":"gdEXvETIHcp7"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qRXrgPDPce2","executionInfo":{"status":"ok","timestamp":1753409565658,"user_tz":-540,"elapsed":7,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"e279df62-653f-45c5-c5de-b03f51e72c2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["device: cpu\n"]}]},{"cell_type":"code","source":["X_train = torch.FloatTensor([[73, 80, 75],\n","                             [93, 88, 93],\n","                             [89, 91, 90],\n","                             [96, 98, 100],\n","                             [73, 66, 70],\n","                             [85, 90, 88],\n","                             [78, 85, 82]]).to(device)\n","\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142], [175], [155]]).to(device)\n","\n","print(X_train, X_train.shape)\n","print(y_train, y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jH4WgXdCQKm3","executionInfo":{"status":"ok","timestamp":1753409565666,"user_tz":-540,"elapsed":7,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"fc33d6c7-914e-4267-a519-b28db183e378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  80.,  75.],\n","        [ 93.,  88.,  93.],\n","        [ 89.,  91.,  90.],\n","        [ 96.,  98., 100.],\n","        [ 73.,  66.,  70.],\n","        [ 85.,  90.,  88.],\n","        [ 78.,  85.,  82.]]) torch.Size([7, 3])\n","tensor([[152.],\n","        [185.],\n","        [180.],\n","        [196.],\n","        [142.],\n","        [175.],\n","        [155.]]) torch.Size([7, 1])\n"]}]},{"cell_type":"code","source":["# y = W1*x1 + W2*x2 + W3*x3 + b\n","model = nn.Linear(3, 1).to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zp39pWcBQoR-","executionInfo":{"status":"ok","timestamp":1753409565675,"user_tz":-540,"elapsed":7,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"4384ff2d-55c6-4d99-b253-e870816ca20c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear(in_features=3, out_features=1, bias=True)\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=0.01)"],"metadata":{"id":"pG_nJ2s2RUu8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Adam**\n","Adam(Adaptive Moment Estimation)은 경사하강법(Gradient Descent)을 개선한 최적화 알고리즘으로, 머신러닝과 딥러닝 모델 학습에서 널리 사용됩니다. Adam은 SGD(Stochastic Gradient Descent)의 단점을 보완하기 위해 개발되었으며, 각 가중치(Weight)와 편향(Bias)마다 다른 학습률(Learning Rate)을 적용해 더욱 효율적이고 안정적으로 최적화를 수행합니다.\n","\n","Adam은 다음 두 가지 아이디어를 결합한 최적화 알고리즘입니다.\n","\n","* **Momentum**: 지금까지의 기울기를 누적해서 방향을 부드럽게 만듦 (관성처럼 움직이기)\n","* **RMSProp**: 각 파라미터마다 학습률을 다르게 조절해서 더 효율적으로 학습\n"],"metadata":{"id":"lVGPGe1IRgA6"}},{"cell_type":"code","source":["loss_fn = nn.MSELoss()"],"metadata":{"id":"TZkk_P0vRam7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 1000\n","for epoch in range(epochs + 1):\n","    y_pred = model(X_train)\n","    loss = loss_fn(y_pred, y_train)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        print(f'Epoch: {epoch}/{epochs}, Loss: {loss.item(): .6f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3gALG3VSjTr","executionInfo":{"status":"ok","timestamp":1753409566425,"user_tz":-540,"elapsed":718,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"e1fa21a2-889c-434e-f58a-81945304211a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0/1000, Loss:  31238.453125\n","Epoch: 100/1000, Loss:  118.153038\n","Epoch: 200/1000, Loss:  12.550371\n","Epoch: 300/1000, Loss:  12.513173\n","Epoch: 400/1000, Loss:  12.471367\n","Epoch: 500/1000, Loss:  12.423098\n","Epoch: 600/1000, Loss:  12.368750\n","Epoch: 700/1000, Loss:  12.308585\n","Epoch: 800/1000, Loss:  12.242879\n","Epoch: 900/1000, Loss:  12.171770\n","Epoch: 1000/1000, Loss:  12.095415\n"]}]},{"cell_type":"code","source":["model.parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGQRMTNfS_T2","executionInfo":{"status":"ok","timestamp":1753409566459,"user_tz":-540,"elapsed":21,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"aa1da808-c90d-4847-b585-692f931ea3be"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7c23fe52c740>"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["for param in model.parameters():\n","    print(param)\n","\n","    # [[0.4640, 0.5508, 0.9735]]: 각각 w1, w2, w3\n","    # [0.1409]: bias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulzcrZ_ITDAF","executionInfo":{"status":"ok","timestamp":1753409566487,"user_tz":-540,"elapsed":25,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"9a157a5d-7ffe-47d8-a2ea-250080c7e6ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[0.4640, 0.5508, 0.9735]], requires_grad=True)\n","Parameter containing:\n","tensor([0.1409], requires_grad=True)\n"]}]},{"cell_type":"code","source":["x_test = torch.FloatTensor([[93, 93, 93]]).to(device)\n","y_pred = model(x_test)\n","print(f\"\\n새로운 입력 데이터 {x_test.tolist()}의 예측 결과: {y_pred.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"976OoVbJTKDC","executionInfo":{"status":"ok","timestamp":1753409566509,"user_tz":-540,"elapsed":6,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"05b36caf-cc41-4a29-80c6-62c4fb68a2cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","새로운 입력 데이터 [[93.0, 93.0, 93.0]]의 예측 결과: 185.0458\n"]}]}]}