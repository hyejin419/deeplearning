{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+CoHAlN3OUqShKdWw0BQm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# 논리 회귀(단층 퍼셉트론)로 XOR 문제 풀기\n","\n","X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = torch.FloatTensor([[0], [1], [1], [0]])\n","\n","model = nn.Sequential(\n","    nn.Linear(2, 1),   # 입력 2차원 → 출력 1차원\n","    nn.Sigmoid()      #  출력층 활성화 함수\n",")\n","\n","optimizer = optim.SGD(model.parameters(), lr=1)\n","\n","epochs = 1000\n","\n","for epoch in range(epochs + 1):\n","    y_pred = model(X)\n","    loss = nn.BCELoss()(y_pred, y)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 100 == 0:\n","        y_bool = (y_pred >= 0.5).float()\n","        accuracy = (y == y_bool).float().sum() / len(y) * 100\n","        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmQZMg-l9MgP","executionInfo":{"status":"ok","timestamp":1753688101987,"user_tz":-540,"elapsed":507,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"7897ca4f-4c9d-4e5b-e5a6-cdaec105484d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 Loss: 0.714461 Accuracy: 25.00%\n","Epoch  100/1000 Loss: 0.693148 Accuracy: 50.00%\n","Epoch  200/1000 Loss: 0.693147 Accuracy: 75.00%\n","Epoch  300/1000 Loss: 0.693147 Accuracy: 75.00%\n","Epoch  400/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch  500/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch  600/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch  700/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch  800/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch  900/1000 Loss: 0.693147 Accuracy: 50.00%\n","Epoch 1000/1000 Loss: 0.693147 Accuracy: 50.00%\n"]}]},{"cell_type":"markdown","source":["은닉층\n",":  입력 데이터를 비선형적으로 변환해, 출력층이 올바른 판단을 내릴 수 있도록 돕는 중간 계산 층으로, 은닉층이 생기면 선형 변환 + 비선형 함수를 반복하면서 복잡한 함수도 학습 가능하고, 뇌처럼 여러 층을 거치며 점점 더 추상적인 특징을 학습할 수 있다."],"metadata":{"id":"J267ynEO2ljh"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","model = nn.Sequential(\n","    nn.Linear(2, 2),   # 입력 2차원 → 은닉층 2노드\n","    nn.Sigmoid(),      # 은닉층 활성화 함수 (은닉층에 비선형형 부여)\n","    nn.Linear(2, 1),   # 은닉층 2노드 → 출력 1노드\n","    nn.Sigmoid()       # 출력층 활성화 함수 (0~1 사이의 범위로 확률화)\n",")\n","\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJ8H1frj3Qjs","executionInfo":{"status":"ok","timestamp":1753688003252,"user_tz":-540,"elapsed":36,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"d246bade-d1dd-4e38-fddf-b1b684c90c15"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=2, out_features=2, bias=True)\n","  (1): Sigmoid()\n","  (2): Linear(in_features=2, out_features=1, bias=True)\n","  (3): Sigmoid()\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 논리 회귀(다층 퍼셉트론)로 XOR 문제 풀기\n","\n","X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = torch.FloatTensor([[0], [1], [1], [0]])\n","\n","optimizer = optim.SGD(model.parameters(), lr=1)\n","\n","epochs = 1000\n","\n","for epoch in range(epochs + 1):\n","    y_pred = model(X)  # 순전파 (예측값 계산. X를 모델에 넣어서 예측값 y_pred 계산.)\n","    loss = nn.BCELoss()(y_pred, y)\n","\n","    optimizer.zero_grad()  # 기존 기울기 초기화\n","    loss.backward()            # 역전파: 기울기 계산\n","    optimizer.step()            # 가중치 업데이트\n","\n","    if epoch % 100 == 0:      # 매 100번마다 중간 결과를 확인\n","        y_bool = (y_pred >= 0.5).float()  # 확률값이 0.5 이상이면 1.0, 아니면 0.0. # float()로 변환: True/False → 1.0/0.0\n","        accuracy = (y == y_bool).float().sum() / len(y) * 100\n","        print(f'Epoch {epoch:4d}/{epochs} Loss: {loss:.6f} Accuracy: {accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hR4HCfFb4s6w","executionInfo":{"status":"ok","timestamp":1753688007657,"user_tz":-540,"elapsed":658,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"fa5b46ae-98a2-41e1-c5fa-64c8e6e5fd64"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0/1000 Loss: 0.854845 Accuracy: 50.00%\n","Epoch  100/1000 Loss: 0.693393 Accuracy: 50.00%\n","Epoch  200/1000 Loss: 0.692602 Accuracy: 50.00%\n","Epoch  300/1000 Loss: 0.689451 Accuracy: 50.00%\n","Epoch  400/1000 Loss: 0.659536 Accuracy: 75.00%\n","Epoch  500/1000 Loss: 0.556877 Accuracy: 75.00%\n","Epoch  600/1000 Loss: 0.456332 Accuracy: 75.00%\n","Epoch  700/1000 Loss: 0.214393 Accuracy: 100.00%\n","Epoch  800/1000 Loss: 0.087342 Accuracy: 100.00%\n","Epoch  900/1000 Loss: 0.049904 Accuracy: 100.00%\n","Epoch 1000/1000 Loss: 0.034142 Accuracy: 100.00%\n"]}]},{"cell_type":"markdown","source":["**옵티마이저의 핵심 역할**\n","\n","순전파: 예측값 계산 (계산만 함)\n","\n","손실 계산: 예측값 vs 정답의 차이 (오차)\n","\n","역전파: 오차를 미분해서 각 가중치가 얼마나 잘못됐는지 계산\n","\n","✅ 옵티마이저:\n","→ 이 미분값(그래디언트)을 사용해서 가중치를 실제로 업데이트!"],"metadata":{"id":"H1eXqbc-5AmX"}},{"cell_type":"markdown","source":["# **비선형 활성화 함수**"],"metadata":{"id":"_evnp88F5BAv"}},{"cell_type":"markdown","source":["- 시그모이드\n","- 하이퍼볼릭 탄젠트\n","- 렐루\n","- 소프트맥스"],"metadata":{"id":"7YcYDvk4_kYI"}},{"cell_type":"code","source":[],"metadata":{"id":"JUUPIAN8_gq0"},"execution_count":null,"outputs":[]}]}